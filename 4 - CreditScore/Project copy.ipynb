{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction - Introdução\n",
    "Questão problema é classificar os clientes, avaliando os riscos em uma consessão de crédito.\n",
    "O modelo criado, irá analisar e decidir se irá aprovar ou negar o pedido de crédito.\n",
    "\n",
    "O dataset está disponvível no link abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Data - Exploração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importando bibliotecas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importando os dados\n",
    "dfMain = pd.read_csv('datasets/crx.data', header = None)\n",
    "dfMain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 690 entries, 0 to 689\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       690 non-null    object \n",
      " 1   1       690 non-null    object \n",
      " 2   2       690 non-null    float64\n",
      " 3   3       690 non-null    object \n",
      " 4   4       690 non-null    object \n",
      " 5   5       690 non-null    object \n",
      " 6   6       690 non-null    object \n",
      " 7   7       690 non-null    float64\n",
      " 8   8       690 non-null    object \n",
      " 9   9       690 non-null    object \n",
      " 10  10      690 non-null    int64  \n",
      " 11  11      690 non-null    object \n",
      " 12  12      690 non-null    object \n",
      " 13  13      690 non-null    object \n",
      " 14  14      690 non-null    int64  \n",
      " 15  15      690 non-null    object \n",
      "dtypes: float64(2), int64(2), object(12)\n",
      "memory usage: 86.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Conhecendo os dados\n",
    "dfMain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    0\n",
       "14    0\n",
       "15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exibindo se há colunas com valores faltantes\n",
    "dfMain.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>690.00000</td>\n",
       "      <td>690.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.758725</td>\n",
       "      <td>2.223406</td>\n",
       "      <td>2.40000</td>\n",
       "      <td>1017.385507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.978163</td>\n",
       "      <td>3.346513</td>\n",
       "      <td>4.86294</td>\n",
       "      <td>5210.102598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.207500</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>395.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               2           7          10             14\n",
       "count  690.000000  690.000000  690.00000     690.000000\n",
       "mean     4.758725    2.223406    2.40000    1017.385507\n",
       "std      4.978163    3.346513    4.86294    5210.102598\n",
       "min      0.000000    0.000000    0.00000       0.000000\n",
       "25%      1.000000    0.165000    0.00000       0.000000\n",
       "50%      2.750000    1.000000    0.00000       5.000000\n",
       "75%      7.207500    2.625000    3.00000     395.500000\n",
       "max     28.000000   28.500000   67.00000  100000.000000"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estatísticas dos dados\n",
    "dfMain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(690, 16)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspecionando valores duplicados\n",
    "dfMain.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotando histograma para analise das distribuições\n",
    "dfMain.hist(figsize=(20,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.298902</td>\n",
       "      <td>0.271207</td>\n",
       "      <td>0.123121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.298902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>0.051345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.271207</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.123121</td>\n",
       "      <td>0.051345</td>\n",
       "      <td>0.063692</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          2         7         10        14\n",
       "2   1.000000  0.298902  0.271207  0.123121\n",
       "7   0.298902  1.000000  0.322330  0.051345\n",
       "10  0.271207  0.322330  1.000000  0.063692\n",
       "14  0.123121  0.051345  0.063692  1.000000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlação entre variáveis numéricas\n",
    "dfMain.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split the dataset - Separando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando biblioteca para separação\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Removendo features que não serão utilizadas, como driver's license e Zip Code. Respectivamente 11,13.\n",
    "dfMain = dfMain.drop([11,13], axis=1)\n",
    "\n",
    "# dfTrain, dfTest = train_test_split(dfMain, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(462, 14)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(228, 14)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning - Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['b' 'a' '?']\n",
      "1 ['30.83' '58.67' '24.50' '27.83' '20.17' '32.08' '33.17' '22.92' '54.42'\n",
      " '42.50' '22.08' '29.92' '38.25' '48.08' '45.83' '36.67' '28.25' '23.25'\n",
      " '21.83' '19.17' '25.00' '47.75' '27.42' '41.17' '15.83' '47.00' '56.58'\n",
      " '57.42' '42.08' '29.25' '42.00' '49.50' '36.75' '22.58' '27.25' '23.00'\n",
      " '27.75' '54.58' '34.17' '28.92' '29.67' '39.58' '56.42' '54.33' '41.00'\n",
      " '31.92' '41.50' '23.92' '25.75' '26.00' '37.42' '34.92' '34.25' '23.33'\n",
      " '23.17' '44.33' '35.17' '43.25' '56.75' '31.67' '23.42' '20.42' '26.67'\n",
      " '36.00' '25.50' '19.42' '32.33' '34.83' '38.58' '44.25' '44.83' '20.67'\n",
      " '34.08' '21.67' '21.50' '49.58' '27.67' '39.83' '?' '37.17' '25.67'\n",
      " '34.00' '49.00' '62.50' '31.42' '52.33' '28.75' '28.58' '22.50' '28.50'\n",
      " '37.50' '35.25' '18.67' '54.83' '40.92' '19.75' '29.17' '24.58' '33.75'\n",
      " '25.42' '37.75' '52.50' '57.83' '20.75' '39.92' '24.75' '44.17' '23.50'\n",
      " '47.67' '22.75' '34.42' '28.42' '67.75' '47.42' '36.25' '32.67' '48.58'\n",
      " '33.58' '18.83' '26.92' '31.25' '56.50' '43.00' '22.33' '32.83' '40.33'\n",
      " '30.50' '52.83' '46.67' '58.33' '37.33' '23.08' '32.75' '68.67' '28.00'\n",
      " '44.00' '25.08' '32.00' '60.58' '40.83' '19.33' '41.33' '56.00' '49.83'\n",
      " '22.67' '27.00' '26.08' '18.42' '21.25' '57.08' '22.42' '48.75' '40.00'\n",
      " '40.58' '28.67' '33.08' '21.33' '41.75' '34.50' '48.17' '27.58' '24.08'\n",
      " '24.83' '36.33' '35.42' '71.58' '39.50' '39.33' '24.33' '60.08' '55.92'\n",
      " '53.92' '18.92' '50.08' '65.42' '17.58' '18.08' '19.67' '25.17' '33.50'\n",
      " '58.42' '26.17' '42.83' '38.17' '20.50' '48.25' '28.33' '18.75' '18.50'\n",
      " '45.00' '40.25' '41.42' '17.83' '18.17' '20.00' '52.17' '50.75' '17.08'\n",
      " '18.33' '59.67' '18.00' '37.58' '30.67' '18.58' '16.25' '21.17' '17.67'\n",
      " '16.50' '29.50' '21.75' '18.25' '35.75' '16.08' '69.17' '32.92' '16.33'\n",
      " '22.17' '57.58' '15.92' '31.75' '19.00' '17.50' '33.67' '30.17' '33.25'\n",
      " '25.25' '34.75' '47.33' '39.08' '42.75' '38.92' '62.75' '32.25' '26.75'\n",
      " '63.33' '30.75' '16.00' '19.50' '32.42' '30.25' '26.83' '16.92' '24.42'\n",
      " '39.42' '23.58' '21.42' '33.00' '26.33' '26.25' '28.17' '20.83' '43.17'\n",
      " '56.83' '15.17' '29.83' '31.00' '51.92' '69.50' '19.58' '22.25' '38.42'\n",
      " '26.58' '35.00' '29.42' '49.17' '51.83' '58.58' '53.33' '27.17' '25.92'\n",
      " '30.58' '17.25' '27.33' '36.50' '29.75' '52.42' '36.17' '34.58' '21.92'\n",
      " '36.58' '31.08' '30.42' '21.08' '17.42' '39.17' '26.50' '17.33' '23.75'\n",
      " '34.67' '74.83' '45.33' '47.25' '24.17' '39.25' '39.00' '64.08' '31.33'\n",
      " '21.00' '13.75' '46.00' '20.25' '60.92' '30.00' '22.83' '45.17' '41.58'\n",
      " '55.75' '25.33' '31.83' '33.92' '24.92' '80.25' '30.08' '48.33' '76.75'\n",
      " '51.33' '41.92' '29.58' '32.17' '51.42' '42.17' '43.08' '59.50' '65.17'\n",
      " '20.33' '48.50' '28.08' '73.42' '51.58' '38.67' '46.08' '20.08' '42.25'\n",
      " '16.17' '47.83' '22.00' '38.33' '25.58' '21.58' '36.08' '38.75' '35.58'\n",
      " '31.58' '15.75' '17.92' '30.33' '47.17' '25.83' '50.25' '36.42']\n",
      "2 [ 0.     4.46   0.5    1.54   5.625  4.     1.04  11.585  4.915  0.83\n",
      "  1.835  6.     6.04  10.5    4.415  0.875  5.875  0.25   8.585 11.25\n",
      "  1.     8.    14.5    6.5    0.585 13.    18.5    8.5   14.79   9.79\n",
      "  7.585  5.125 10.75   1.5    1.585 11.75   9.415  9.17  15.     1.415\n",
      " 13.915 28.     6.75   2.04   0.665  2.5    3.    11.625  4.5   12.25\n",
      " 16.165  0.79   0.835  4.25   0.375 25.125  7.5    5.     7.     5.29\n",
      "  1.165  9.75  19.     3.5    0.625  2.21  12.75  15.5    1.375  3.54\n",
      " 11.     1.75  16.5   12.     2.25   0.75  12.5    1.25   1.125  7.04\n",
      " 10.335  6.21   6.665  9.     5.5    0.54   2.75   9.5   13.5    3.75\n",
      " 16.     0.29   1.665  7.54   0.46  10.    11.5    3.04   2.     0.08\n",
      "  1.71   3.25   2.54  13.585  8.665  9.25   8.17   2.335 19.5    5.665\n",
      "  4.625  0.205  0.96   4.04   5.04   3.165  7.625 10.04  10.25   2.125\n",
      "  9.335  6.625  2.71   9.625 12.54   9.54   8.46  13.75  21.    10.125\n",
      " 25.085  0.21  21.5   11.125 11.045  1.335  0.085  1.21   0.165  5.71\n",
      "  5.415 12.625  0.58   0.415  2.415  0.335  3.125 12.125  2.875 13.665\n",
      " 26.335 10.29   1.29  22.     0.125  1.085  4.085  4.71   6.165  4.585\n",
      " 11.46  14.585  0.17   1.625  2.085  5.085  8.125  2.835  1.79   0.705\n",
      "  2.165  2.29  18.125  3.085 11.665  4.125  1.08  13.335 11.835  4.79\n",
      "  9.96   7.08  25.21   0.67   3.79  22.29   3.335  0.42   1.46   0.04\n",
      " 12.33  12.335  0.915 14.    17.75  20.     5.25   4.165 10.915  4.75\n",
      " 10.415  7.835  0.71   2.46   9.585  3.625  2.665  5.835 12.835 10.665\n",
      "  7.25  10.21   3.29  10.085  3.375]\n",
      "3 ['u' 'y' '?' 'l']\n",
      "4 ['g' 'p' '?' 'gg']\n",
      "5 ['w' 'q' 'm' 'r' 'cc' 'k' 'c' 'd' 'x' 'i' 'e' 'aa' 'ff' 'j' '?']\n",
      "6 ['v' 'h' 'bb' 'ff' 'j' 'z' '?' 'o' 'dd' 'n']\n",
      "7 [ 1.25   3.04   1.5    3.75   1.71   2.5    6.5    0.04   3.96   3.165\n",
      "  2.165  4.335  1.     5.     0.25   0.96   3.17   0.665  0.75   0.835\n",
      "  7.875  3.085  0.5    5.165 15.     7.     5.04   7.96   7.585  0.415\n",
      "  2.     1.835 14.415  4.5    5.335  8.625 28.5    2.625  0.125  6.04\n",
      "  3.5    0.165  0.875  1.75   0.     7.415  0.085  5.75   6.     3.\n",
      "  1.585  4.29   1.54   1.46   1.625 12.5   13.5   10.75   0.375  0.585\n",
      "  0.455  4.     8.5    9.46   2.25  10.     0.795  1.375  1.29  11.5\n",
      "  6.29  14.     0.335  1.21   7.375  7.5    3.25  13.     5.5    4.25\n",
      "  0.625  5.085  2.75   2.375  8.     1.085  2.54   4.165  1.665 11.\n",
      "  9.     1.335  1.415  1.96   2.585  5.125 15.5    0.71   5.665 18.\n",
      "  5.25   8.665  2.29  20.     2.46  13.875  2.085  4.58   2.71   2.04\n",
      "  0.29   4.75   0.46   0.21   0.54   3.335  2.335  1.165  2.415  2.79\n",
      "  4.625  1.04   6.75   1.875 16.    12.75   5.375  2.125 17.5    3.125\n",
      "  0.79   8.29 ]\n",
      "8 ['t' 'f']\n",
      "9 ['t' 'f']\n",
      "10 [ 1  6  0  5  7 10  3 17  2  9  8 15 11 12 40 23  4 20 67 14 16 13 19]\n",
      "12 ['g' 's' 'p']\n",
      "14 [     0    560    824      3  31285   1349    314   1442    200   2690\n",
      "    245   1208   1260     11  10000   5000   4000     35    713    551\n",
      "    500    300    221   2283    100     15    284   1236   5800    730\n",
      "    400  50000    456  15108   2954      2     20     27    225      1\n",
      "     38      5    130    147    210  11202   1332     50    258    567\n",
      "   1000   2510    809    610    150  51100    367    600    247    375\n",
      "    278    827   2072    582   2300   3065   2200      6   1602   2184\n",
      "   3376   2000   7544  10561    837  11177    639   2028   1065    540\n",
      "    158  15000   3000   3257   1655   1430      7    790    396    678\n",
      "   1187   6590    168   1270   1210    742   8851   7059   1704    857\n",
      "   6700   2503   9800    196     14  26726  18027     99    444   1200\n",
      "   2010     13    120     32    722     40    484    204     98   5552\n",
      "    105   2803    126      4     21    173     10     25     42 100000\n",
      "    113      8     44   2732    179     16   1062    251    228     67\n",
      "     12    122   4208   1300    112   1110   1004    286   4500   1212\n",
      "    195     87     17    184    140     18    146     22     55     70\n",
      "     60   1058    769   5200     19    316    350   3552    687   1950\n",
      "     53     41     33     80    351   2100    475    892   4607   2206\n",
      "   5860     28   1391   2279    591    960    690    234    800    990\n",
      "   2197     90    340    347    327   4071    109   1249    134   1344\n",
      "    321    948   2079   2384    458   5298    162   1583     58     59\n",
      "   1400   1465   8000   4700   1097   3290  13212   5777   5124     23\n",
      "   4159    918    768    283    108      9     68    587    141    501\n",
      "    160    390    154    117    246    237    364    537    394    750]\n",
      "15 ['+' '-']\n"
     ]
    }
   ],
   "source": [
    "#Interando nas colunas para perceber se há algum valor diferente do esperado\n",
    "for i in dfTrain.columns:\n",
    "    print(i, dfMain[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['a' 'b' '?']\n",
      "1 ['?' '46.00' '20.00' '47.33' '19.17' '24.33' '21.58' '25.00' '21.92'\n",
      " '23.50' '40.83' '22.67' '21.67' '30.58' '20.17' '27.83' '16.08' '37.33'\n",
      " '29.83' '16.00' '34.75' '21.75' '23.92' '40.25' '34.25' '22.50' '27.67'\n",
      " '36.25' '39.92' '19.75' '38.67' '20.67' '60.08' '35.25' '18.50' '47.42'\n",
      " '21.83' '38.58' '30.75' '43.08' '34.17' '64.08' '38.92' '34.00' '34.08'\n",
      " '22.75' '18.17' '62.50' '30.33' '22.08' '20.42' '30.17' '26.92' '48.33'\n",
      " '15.75' '42.00' '50.08' '16.17' '35.75' '39.33' '23.33' '48.58' '24.83'\n",
      " '24.50' '36.50' '23.42' '21.08' '21.25' '25.75' '25.83' '19.67' '22.42'\n",
      " '19.42' '30.25' '56.75' '30.50' '29.25' '35.17' '20.50' '18.83' '56.42'\n",
      " '57.08' '32.33' '60.58' '41.58' '41.17' '69.50' '18.08' '24.92' '45.17'\n",
      " '57.83' '50.75' '54.58' '32.25' '41.75' '33.17' '69.17' '22.58' '23.25'\n",
      " '32.83' '42.75' '23.08' '51.83' '36.67' '27.58' '29.58' '28.92' '40.92'\n",
      " '35.58' '23.17' '25.25' '24.75' '28.00' '28.17' '24.58' '29.17' '39.83'\n",
      " '26.00' '53.92' '16.50' '25.42' '16.25' '31.83' '48.08' '33.67' '31.67'\n",
      " '27.25' '39.00' '42.08' '30.42' '47.25' '22.92' '35.00' '16.92' '33.25'\n",
      " '19.50' '48.17' '19.58' '15.17' '24.08' '32.00' '43.17' '20.08' '39.08'\n",
      " '18.58' '17.33' '32.75' '49.00' '22.83' '33.08' '39.42' '80.25' '36.33'\n",
      " '31.25' '57.42' '39.58' '29.67' '44.25' '39.50' '42.25' '36.00' '29.92'\n",
      " '18.42' '17.08' '43.25' '26.67' '26.08' '25.67' '27.33' '29.75' '21.50'\n",
      " '27.42' '20.83' '58.42' '36.17' '19.00']\n",
      "2 [ 1.5    4.     0.     6.5    6.625  0.79  12.5    0.5   11.045 10.\n",
      "  0.165  1.165 10.665  9.25   1.     0.335  2.665  2.04   2.5    1.75\n",
      "  0.54   0.585  3.5   21.5    3.     0.415  0.75   5.     0.21   1.835\n",
      " 14.5    3.165  2.     8.    11.     1.585  0.375  2.75  20.     1.665\n",
      "  5.085 11.5   12.75   0.83   0.835  7.     2.25  12.     9.79  12.54\n",
      "  0.04   0.915  5.875 11.625  4.5    8.46   4.25  10.085  6.21  12.835\n",
      " 11.25   7.25   5.5   12.25  14.79  25.125 11.835  9.54  28.     7.5\n",
      " 16.5    1.335  6.     1.25   1.54   0.665  7.04   9.415 14.     0.96\n",
      "  1.04   9.    10.04  12.625  4.085  3.25  15.    13.5    9.625  0.125\n",
      "  0.25   3.75  13.335  2.165 16.165  0.29   2.335  1.375  2.415 10.5\n",
      "  5.71   9.5    4.75  11.585  1.625  1.71   2.125  8.5   13.915  1.415\n",
      "  2.29   0.085 25.21   8.665  9.75   4.415 21.     0.42 ]\n",
      "3 ['u' 'y' 'l']\n",
      "4 ['g' 'p' 'gg']\n",
      "5 ['ff' 'j' 'd' 'c' 'm' 'cc' 'aa' 'w' 'q' 'k' 'x' 'i' 'e' 'r' '?']\n",
      "6 ['ff' 'j' 'v' 'bb' 'h' 'z' 'n' '?' 'dd']\n",
      "7 [ 0.     0.5    1.     5.5    0.665  3.     0.125  2.     0.875  1.75\n",
      "  2.25   2.5    0.085  1.665  0.165  0.04  20.     7.415  0.335  5.\n",
      "  0.795  2.085 18.     3.75   1.5    6.5    0.29  13.5    0.585  0.375\n",
      " 17.5    0.25   1.085  0.415  2.165  1.585 16.     7.96   2.29   1.625\n",
      "  0.75  10.     0.835  6.     2.46   3.5    1.25   4.     5.04  28.5\n",
      " 11.     0.21   4.75   1.54  14.    14.415 13.875  2.75   5.085  7.5\n",
      "  5.335  1.835  4.165  8.665  5.375  4.25   1.335  0.54   5.75   1.375\n",
      "  4.5    8.5    1.29   0.625  7.     8.625 10.75   4.335  1.21   1.415\n",
      "  3.085  2.335]\n",
      "8 ['f' 't']\n",
      "9 ['t' 'f']\n",
      "10 [ 2  0  1 12  3 11  6  5 15  8  9  4 14  7 40 19 10 16 13]\n",
      "12 ['g' 's' 'p']\n",
      "14 [  105   960     0   228     1   837    20     3    28   537   126   501\n",
      "    59  1200   251   367  2279  1000     5  2503   300 51100   162   200\n",
      "   390   540  4000    18  1391  1583     6   824    50     8    23     2\n",
      "    99   321     9   150  3065   500    15  2197 10561   444 50000  1332\n",
      "   600 31285  1704   396  5552  2072   100  4208   742   394  2283  1062\n",
      "   134   475   730   108 10000    33   892  1058  3000    10   210    68\n",
      "  1270  1349    27   800   340  1187 11177  1210   456   246  2384   722\n",
      "    90  5777    21    11  6700]\n",
      "15 ['-' '+']\n"
     ]
    }
   ],
   "source": [
    "for i in dfTest:\n",
    "    print(i, dfTest[i].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando biblioteca numpy\n",
    "import numpy as np\n",
    "\n",
    "#Substituindo '?' por NaN\n",
    "dfTrain[0] = dfTrain[0].replace('?', np.NaN)\n",
    "dfTest[0] = dfTest[0].replace('?', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['a', 'b', nan], dtype=object), array(['a', 'b', nan], dtype=object))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exibindo valores da primeira coluna\n",
    "dfTrain[0].unique(), dfTest[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2985/2318783880.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfTrain.fillna(dfTrain.mean(), inplace=True)\n",
      "/tmp/ipykernel_2985/2318783880.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  dfTest.fillna(dfTest.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Substuindo valores faltantes pela mediana\n",
    "dfTrain.fillna(dfTrain.mean(), inplace=True)\n",
    "dfTest.fillna(dfTest.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0     8\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 12    0\n",
       " 14    0\n",
       " 15    0\n",
       " dtype: int64,\n",
       " 0     4\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 12    0\n",
       " 14    0\n",
       " 15    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.isnull().sum(), dfTest.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0     0\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 12    0\n",
       " 14    0\n",
       " 15    0\n",
       " dtype: int64,\n",
       " 0     0\n",
       " 1     0\n",
       " 2     0\n",
       " 3     0\n",
       " 4     0\n",
       " 5     0\n",
       " 6     0\n",
       " 7     0\n",
       " 8     0\n",
       " 9     0\n",
       " 10    0\n",
       " 12    0\n",
       " 14    0\n",
       " 15    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Substituindo valores não numericos (categóricos)\n",
    "for col in dfTrain.columns:\n",
    "    #Checando o tipo da coluna\n",
    "    if dfTrain[col].dtypes == 'object':\n",
    "        #Realizando a substiuição\n",
    "        dfTrain = dfTrain.fillna(dfTrain[col].value_counts().index[0])\n",
    "        dfTest = dfTest.fillna(dfTest[col].value_counts().index[0])\n",
    "        \n",
    "#Exibindo valores nulos        \n",
    "dfTrain.isnull().sum(), dfTest.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Pre-processing - Pré-processamento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convertendo dados categóricos em numéricos\n",
    "dfTrain = pd.get_dummies(dfTrain)\n",
    "dfTest = pd.get_dummies(dfTest)\n",
    "\n",
    "#Usando reindex para evitar erro nas predicções usando matrizes\n",
    "dfTest = dfTest.reindex(columns=dfTrain.columns, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalonando os dados\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Separando os dados de treino e teste\n",
    "X_train, y_train = dfTrain.iloc[:, :-1].values, dfTrain.iloc[:, [-1]].values\n",
    "X_test, y_test = dfTest.iloc[:,:-1].values, dfTest.iloc[:,[-1]].values\n",
    "\n",
    "#Instanciando o objeto\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "#Padronizando os dados de treino e teste\n",
    "rescaledX_train = scaler.fit_transform(X_train)\n",
    "rescaledX_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>14</th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_b</th>\n",
       "      <th>1_13.75</th>\n",
       "      <th>1_15.83</th>\n",
       "      <th>1_15.92</th>\n",
       "      <th>1_16.00</th>\n",
       "      <th>...</th>\n",
       "      <th>6_z</th>\n",
       "      <th>8_f</th>\n",
       "      <th>8_t</th>\n",
       "      <th>9_f</th>\n",
       "      <th>9_t</th>\n",
       "      <th>12_g</th>\n",
       "      <th>12_p</th>\n",
       "      <th>12_s</th>\n",
       "      <th>15_+</th>\n",
       "      <th>15_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2.500</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0</td>\n",
       "      <td>456</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2.750</td>\n",
       "      <td>4.25</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1.500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1.085</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.125</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 334 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2     7  10    14  0_a  0_b  1_13.75  1_15.83  1_15.92  1_16.00  ...  \\\n",
       "382  2.500  4.50   0   456    1    0        0        0        0        0  ...   \n",
       "137  2.750  4.25   6     0    0    1        0        0        0        0  ...   \n",
       "346  1.500  0.25   0   122    0    1        0        0        0        0  ...   \n",
       "326  1.085  0.04   0   179    0    1        0        0        0        0  ...   \n",
       "33   5.125  5.00   0  4000    1    0        0        0        0        0  ...   \n",
       "\n",
       "     6_z  8_f  8_t  9_f  9_t  12_g  12_p  12_s  15_+  15_-  \n",
       "382    0    1    0    1    0     1     0     0     0     1  \n",
       "137    0    0    1    0    1     1     0     0     1     0  \n",
       "346    0    1    0    1    0     1     0     0     0     1  \n",
       "326    0    1    0    1    0     1     0     0     0     1  \n",
       "33     0    0    1    1    0     1     0     0     1     0  \n",
       "\n",
       "[5 rows x 334 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [462, 228]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/marcus/Área de Trabalho/projetosDS/Data-Science-projects/4 - CreditScore/Project.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X \u001b[39m=\u001b[39m dfTrain\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m dfTest\u001b[39m.\u001b[39miloc[:,[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X44sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size \u001b[39m=\u001b[39;49m \u001b[39m0.3\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2442\u001b[0m \u001b[39mif\u001b[39;00m n_arrays \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2443\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt least one array required as input\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2445\u001b[0m arrays \u001b[39m=\u001b[39m indexable(\u001b[39m*\u001b[39;49marrays)\n\u001b[1;32m   2447\u001b[0m n_samples \u001b[39m=\u001b[39m _num_samples(arrays[\u001b[39m0\u001b[39m])\n\u001b[1;32m   2448\u001b[0m n_train, n_test \u001b[39m=\u001b[39m _validate_shuffle_split(\n\u001b[1;32m   2449\u001b[0m     n_samples, test_size, train_size, default_test_size\u001b[39m=\u001b[39m\u001b[39m0.25\u001b[39m\n\u001b[1;32m   2450\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:433\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    432\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[0;32m--> 433\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[1;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [462, 228]"
     ]
    }
   ],
   "source": [
    "X = dfTrain.iloc[:, :-1]\n",
    "y = dfTest.iloc[:,[-1]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buildin a Model - Construindo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marcus/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [228, 462]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/marcus/Área de Trabalho/projetosDS/Data-Science-projects/4 - CreditScore/Project.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X40sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m log\u001b[39m.\u001b[39mfit(rescaledX_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X40sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#Exibindo a acurácia do modelo\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X40sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA acurácia do modelo é \u001b[39m\u001b[39m{\u001b[39;00mlog\u001b[39m.\u001b[39mscore(rescaledX_train, y_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:666\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    642\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 666\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39;49msample_weight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    213\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    390\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [228, 462]"
     ]
    }
   ],
   "source": [
    "#Imporando LogisticRegression\n",
    "from sklearn.linear_model  import LogisticRegression\n",
    "\n",
    "#Instanciando\n",
    "log = LogisticRegression()\n",
    "\n",
    "#Treinando \n",
    "log.fit(rescaledX_train, y_train)\n",
    "\n",
    "\n",
    "#Exibindo a acurácia do modelo\n",
    "print(f\"A acurácia do modelo é {log.score(rescaledX_train, y_test)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 466)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaledX_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions - Fazendo previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 298 features, but LogisticRegression is expecting 466 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/marcus/Área de Trabalho/projetosDS/Data-Science-projects/4 - CreditScore/Project.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X60sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X60sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#Prevendo\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X60sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m log\u001b[39m.\u001b[39;49mpredict(rescaledX_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X60sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#Exibindo a acurácia do modelo\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/marcus/%C3%81rea%20de%20Trabalho/projetosDS/Data-Science-projects/4%20-%20CreditScore/Project.ipynb#X60sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mA acurácia do modelo é \u001b[39m\u001b[39m{\u001b[39;00mlog\u001b[39m.\u001b[39mscore(rescaledX_test, y_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:447\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    434\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 447\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    448\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    449\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py:429\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    427\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 429\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    430\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    431\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 298 features, but LogisticRegression is expecting 466 features as input."
     ]
    }
   ],
   "source": [
    "#Importando matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Prevendo\n",
    "y_pred = log.predict(rescaledX_test)\n",
    "\n",
    "#Exibindo a acurácia do modelo\n",
    "print(f\"A acurácia do modelo é {log.score(rescaledX_test, y_test)}\" )\n",
    "\n",
    "#Plotando matriz de confusão\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad4078168b69d66fe05634f3b7be757ef4015f974a20b20ffdc4b2de487ad266"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
